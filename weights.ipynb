{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvpp4lbb2Maq6hr9bhOVPU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download PyTorch Weights of Pretrained Models\n",
        "\n",
        "The notebook uses [PyTorch](https://pytorch.org/) to access pretrained weights and biases of pretrained models. It then converts all tensors to [NumPy](https://numpy.org/) floating point and saves them in a custom file."
      ],
      "metadata": {
        "id": "RqXbCLzpPQJt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "MI055r3Y3rpr"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "#@markdown Run this cell to install PyTorch and its dependencies.\n",
        "!pip -q install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Modules\n",
        "#@markdown The only modules needed are the *torchvision* module to access the\n",
        "#@markdown pretrained weights, and the *joblib* library to save (pickle) the\n",
        "#@markdown weights to file. The download is dealt with *colab* native libraries.\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import joblib\n",
        "from google.colab import files\n",
        "from torchvision.models import get_weight"
      ],
      "metadata": {
        "cellView": "form",
        "id": "DAwSnOHZ4tE2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Weights Download\n",
        "#@markdown The full list of available models and weights can be found in the \n",
        "#@markdown [docs](https://pytorch.org/vision/stable/models.html) (case \n",
        "#@markdown sensitive). Notice that not all combinations of model-parameter are\n",
        "#@markdown available. The \"DEFAULT\" choice loads the set of weights providing\n",
        "#@markdown the best results on [ImageNet](https://www.kaggle.com/c/imagenet-object-localization-challenge).\n",
        "#@markdown Weights are saved as **ordered dictionary** in the specified file.\n",
        "#@markdown\n",
        "#@markdown *N.B.: the default GoogLeNet is the InceptionV1.*\n",
        "\n",
        "model = \"GoogLeNet\" #@param [\"AlexNet\", \"ConvNeXt_Base\", \"ConvNeXt_Large\", \"ConvNeXt_Small\", \"ConvNeXt_Tiny\", \"DenseNet121\", \"DenseNet161\", \"DenseNet169\", \"DenseNet201\", \"EfficientNet_B0\", \"EfficientNet_B1\", \"EfficientNet_B2\", \"EfficientNet_B3\", \"EfficientNet_B4\", \"EfficientNet_B5\", \"EfficientNet_B6\", \"EfficientNet_B7\", \"EfficientNet_V2_L\", \"EfficientNet_V2_M\", \"EfficientNet_V2_S\", \"GoogLeNet\", \"Inception_V3\", \"MNASNet0_5\", \"MNASNet0_75\", \"MNASNet1_0\", \"MNASNet1_3\", \"MobileNet_V2\", \"MobileNet_V3_Large\", \"MobileNet_V3_Small\", \"RegNet_X_16GF\", \"RegNet_X_1_6GF\", \"RegNet_X_32GF\", \"RegNet_X_3_2GF\", \"RegNet_X_400MF\", \"RegNet_X_800MF\", \"RegNet_X_8GF\", \"RegNet_Y_128GF\", \"RegNet_Y_16GF\", \"RegNet_Y_1_6GF\", \"RegNet_Y_32GF\", \"RegNet_Y_3_2GF\", \"RegNet_Y_400MF\", \"RegNet_Y_800MF\", \"RegNet_Y_8GF\", \"ResNeXt101_32X8D\", \"ResNeXt101_64X4D\", \"ResNeXt50_32X4D\", \"ResNet101\", \"ResNet152\", \"ResNet18\", \"ResNet34\", \"ResNet50\", \"ShuffleNet_V2_X0_5\", \"ShuffleNet_V2_X1_0\", \"ShuffleNet_V2_X1_5\", \"ShuffleNet_V2_X2_0\", \"SqueezeNet1_0\", \"SqueezeNet1_1\", \"Swin_B\", \"Swin_S\", \"Swin_T\", \"VGG11\", \"VGG11_BN\", \"VGG13\", \"VGG13_BN\", \"VGG16\", \"VGG16_BN\", \"VGG19\", \"VGG19_BN\", \"ViT_B_16\", \"ViT_B_32\", \"ViT_H_14\", \"ViT_L_16\", \"ViT_L_32\", \"Wide_ResNet101_2\", \"Wide_ResNet50_2\"] {type: \"string\"}\n",
        "weights = \"DEFAULT\" #@param [\"DEFAULT\", \"IMAGENET1K_V1\", \"IMAGENET1K_V2\", \"IMAGENET1K_SWAG_LINEAR_V1\", \"IMAGENET1K_SWAG_E2E_V1\", \"IMAGENET1K_FEATURES\"] {type: \"string\"}\n",
        "output = \"weights.joblib\" #@param {type: \"string\"}\n",
        "try:\n",
        "  load_weights = get_weight(f'{model}_Weights.{weights}')\n",
        "  tensors_dict = load_weights.get_state_dict(progress=False)\n",
        "  \n",
        "  # convert to numpy arrays\n",
        "  for name, tensor in tensors_dict.items():\n",
        "    tensors_dict[name] = tensor.numpy().astype(float)\n",
        "  \n",
        "  # save to file\n",
        "  path = joblib.dump(tensors_dict, output)\n",
        "  \n",
        "  # print status\n",
        "  print(f'Tensors saved to {path[0]}. Beginning download...')\n",
        "  files.download(path[0])\n",
        "except ValueError:\n",
        "  print(f'There are no {weights} weights for the model {model}! Try using \"IMAGENET1K_V1\" or the \"DEFAULT\" choice.')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "P7mmWdE6En1C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}