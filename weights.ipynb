{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOmQC20gWhTZKt7Jef7Tz6/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Download PyTorch Weights of Pretrained Models\n","\n","The notebook uses [PyTorch](https://pytorch.org/) to access pretrained weights and biases of pretrained models. It then converts all tensors to [NumPy](https://numpy.org/) floating point and saves them in a custom file."],"metadata":{"id":"RqXbCLzpPQJt"}},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"MI055r3Y3rpr","executionInfo":{"status":"ok","timestamp":1664354995047,"user_tz":-120,"elapsed":4263,"user":{"displayName":"Riccardo Finotello","userId":"10227658340086575254"}}},"outputs":[],"source":["#@title Install Dependencies\n","#@markdown Run this cell to install PyTorch and its dependencies.\n","!pip -q install torch torchvision"]},{"cell_type":"code","source":["#@title Import Modules\n","#@markdown The only modules needed are the *torchvision* module to access the\n","#@markdown pretrained weights, and the *joblib* library to save (pickle) the\n","#@markdown weights to file. The download is dealt with *colab* native libraries.\n","%load_ext autoreload\n","%autoreload 2\n","\n","import joblib\n","from google.colab import files\n","from torchvision.models import get_weight"],"metadata":{"cellView":"form","id":"DAwSnOHZ4tE2","executionInfo":{"status":"ok","timestamp":1664354997625,"user_tz":-120,"elapsed":2596,"user":{"displayName":"Riccardo Finotello","userId":"10227658340086575254"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title Model Weights Download\n","#@markdown The full list of available models and weights can be found in the \n","#@markdown [docs](https://pytorch.org/vision/stable/models.html) (case \n","#@markdown sensitive). Notice that not all combinations of model-parameter are\n","#@markdown available. The \"DEFAULT\" choice loads the set of weights providing\n","#@markdown the best results on [ImageNet](https://www.kaggle.com/c/imagenet-object-localization-challenge).\n","#@markdown Weights are saved as **ordered dictionary** in the specified file.\n","#@markdown\n","#@markdown *N.B.: the default GoogLeNet is the InceptionV1.*\n","\n","model = \"GoogLeNet\" #@param [\"AlexNet\", \"ConvNeXt_Base\", \"ConvNeXt_Large\", \"ConvNeXt_Small\", \"ConvNeXt_Tiny\", \"DenseNet121\", \"DenseNet161\", \"DenseNet169\", \"DenseNet201\", \"EfficientNet_B0\", \"EfficientNet_B1\", \"EfficientNet_B2\", \"EfficientNet_B3\", \"EfficientNet_B4\", \"EfficientNet_B5\", \"EfficientNet_B6\", \"EfficientNet_B7\", \"EfficientNet_V2_L\", \"EfficientNet_V2_M\", \"EfficientNet_V2_S\", \"GoogLeNet\", \"Inception_V3\", \"MNASNet0_5\", \"MNASNet0_75\", \"MNASNet1_0\", \"MNASNet1_3\", \"MobileNet_V2\", \"MobileNet_V3_Large\", \"MobileNet_V3_Small\", \"RegNet_X_16GF\", \"RegNet_X_1_6GF\", \"RegNet_X_32GF\", \"RegNet_X_3_2GF\", \"RegNet_X_400MF\", \"RegNet_X_800MF\", \"RegNet_X_8GF\", \"RegNet_Y_128GF\", \"RegNet_Y_16GF\", \"RegNet_Y_1_6GF\", \"RegNet_Y_32GF\", \"RegNet_Y_3_2GF\", \"RegNet_Y_400MF\", \"RegNet_Y_800MF\", \"RegNet_Y_8GF\", \"ResNeXt101_32X8D\", \"ResNeXt101_64X4D\", \"ResNeXt50_32X4D\", \"ResNet101\", \"ResNet152\", \"ResNet18\", \"ResNet34\", \"ResNet50\", \"ShuffleNet_V2_X0_5\", \"ShuffleNet_V2_X1_0\", \"ShuffleNet_V2_X1_5\", \"ShuffleNet_V2_X2_0\", \"SqueezeNet1_0\", \"SqueezeNet1_1\", \"Swin_B\", \"Swin_S\", \"Swin_T\", \"VGG11\", \"VGG11_BN\", \"VGG13\", \"VGG13_BN\", \"VGG16\", \"VGG16_BN\", \"VGG19\", \"VGG19_BN\", \"ViT_B_16\", \"ViT_B_32\", \"ViT_H_14\", \"ViT_L_16\", \"ViT_L_32\", \"Wide_ResNet101_2\", \"Wide_ResNet50_2\"] {type: \"string\"}\n","weights = \"DEFAULT\" #@param [\"DEFAULT\", \"IMAGENET1K_V1\", \"IMAGENET1K_V2\", \"IMAGENET1K_SWAG_LINEAR_V1\", \"IMAGENET1K_SWAG_E2E_V1\", \"IMAGENET1K_FEATURES\"] {type: \"string\"}\n","output = \"weights.joblib\" #@param {type: \"string\"}\n","load_weights = get_weight(f'{model}_Weights.{weights}')\n","\n","tensors_dict = load_weights.get_state_dict(progress=False)\n","\n","# convert to numpy arrays\n","for name, tensor in tensors_dict.items():\n","  tensors_dict[name] = tensor.numpy().astype(float)\n","\n","# save to file\n","path = joblib.dump(tensors_dict, output)\n","\n","# print status\n","print(f'Tensors saved to {path[0]}. Beginning download...')\n","files.download(path[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":69},"cellView":"form","id":"P7mmWdE6En1C","executionInfo":{"status":"ok","timestamp":1664354998802,"user_tz":-120,"elapsed":1192,"user":{"displayName":"Riccardo Finotello","userId":"10227658340086575254"}},"outputId":"872bd31e-3d84-453f-fed3-5013f192b8a4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n"]},{"output_type":"stream","name":"stdout","text":["Tensors saved to weights.joblib. Beginning download...\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9a8af7b6-e84b-4371-88a6-0e440fc7fc9d\", \"weights.joblib\", 104201537)"]},"metadata":{}}]}]}