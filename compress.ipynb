{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM+HdIjQBFVeNKTq8txODTs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compression of Weights\n",
        "\n",
        "In this notebook we use the `tensorly` library to compress the weights of neural networks. We focus on *PARAFAC* and *TUCKER* decomposition to start with. The notebook takes a set of weights in NumPy format as input (a dictionary of keys name --> tensor) and outputs a dictionary in the same format."
      ],
      "metadata": {
        "id": "_28hugkTgerX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "DZuJvnC1f3L1"
      },
      "outputs": [],
      "source": [
        "#@title Install Dependencies\n",
        "#@markdown Run this cell to install all needed depedencies.\n",
        "!pip -q install tensorly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Modules\n",
        "#@markdown We need to import the decomposition (and reconstruction) modules to\n",
        "#@markdown reduce the rank of the tensors.\n",
        "import joblib\n",
        "from tensorly.decomposition import parafac, tucker\n",
        "from tensorly.cp_tensor import cp_to_tensor\n",
        "from tensorly.tucker_tensor import tucker_to_tensor\n",
        "from google.colab import files\n",
        "\n",
        "methods = {'parafac': (parafac, cp_to_tensor),\n",
        "           'tucker': (tucker, tucker_to_tensor)\n",
        "           }\n",
        "method = \"parafac\" #@param ['parafac', 'tucker'] {type: \"string\"}\n",
        "rank = 2 #@param {type: \"integer\"}\n",
        "init = \"random\" #@param ['random', 'svd'] {type: \"string\"}\n",
        "decomp, recons = methods[method]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NDneuOHGgvv0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload the Weights\n",
        "#@markdown We first upload the data in dictionary (name -> tensor) format.\n",
        "upload = files.upload()\n",
        "tensors_dict = joblib.load(list(upload.keys())[0])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n1L4ILqWSrPp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compute the Decomposition\n",
        "#@markdown Compute the decomposition and reconstruction of the weights of the\n",
        "#@markdown network. We choose a **limit** in the number of the tensors to\n",
        "#@markdown process as it is a **memory-consuming** operation: the manual limit\n",
        "#@markdown allows for the computation to finish **without crashing the \n",
        "#@markdown notebook** (`limit` $\\le 0$ disables the counter).\n",
        "limit = -1 #@param {type: \"integer\"}\n",
        "scanned_tensors = 0\n",
        "for name, tensor in tensors_dict.items():\n",
        "\n",
        "  if scanned_tensors > limit and limit > 0: break\n",
        "\n",
        "  if tensor.ndim > 2 and \"weight\" in name:\n",
        "\n",
        "    print(f'Scanning {name} of shape {list(tensor.shape)}...')\n",
        "\n",
        "    # decomposition\n",
        "    tensor_decomp = decomp(tensor, rank, init=init)\n",
        "\n",
        "    # recompose the tensor\n",
        "    tensor_recons = recons(tensor_decomp)\n",
        "\n",
        "    # substitute the tensor\n",
        "    tensors_dict[name] = tensor\n",
        "\n",
        "    # counter\n",
        "    scanned_tensors += 1\n",
        "\n",
        "  else:\n",
        "\n",
        "    print(f'> Skipping {name}...')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zG_B7Al3ZQmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download the Tensors\n",
        "#@markdown After the computation of the decomposition, we recover the reduced\n",
        "#@markdown tensors.\n",
        "weights_output = \"weights_modified.joblib\" #@param {type: \"string\"}\n",
        "path = joblib.dump(tensors_dict, weights_output)\n",
        "print(f'Weights saved to {path[0]}. Beginning download...')\n",
        "files.download(path[0])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1h17LRcablgo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}